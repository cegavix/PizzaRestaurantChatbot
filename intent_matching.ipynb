{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resource: wordnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/julia.clegg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Download NLTK resources if necessary \n",
    "def download_nltk_resources():\n",
    "    # Resources to download resources \n",
    "    # Try except : catch the errors rather than print to the user \n",
    "    resources = {\n",
    "        \"tokenizers/punkt\": \"punkt\",\n",
    "        \"corpora/wordnet\": \"wordnet\",\n",
    "        \"taggers/averaged_perceptron_tagger\": \"averaged_perceptron_tagger\",\n",
    "        \"corpora/stopwords\": \"stopwords\"\n",
    "    }\n",
    "    for resource_path, resource_id in resources.items():\n",
    "        try:\n",
    "            # Check if the resource is available, and download if it is not\n",
    "            nltk.data.find(resource_path)\n",
    "        except LookupError:\n",
    "            print(f\"Downloading NLTK resource: {resource_id}\")\n",
    "            nltk.download(resource_id)\n",
    "\n",
    "# Call the function at the start of your script\n",
    "download_nltk_resources()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T13:37:32.332647Z",
     "start_time": "2023-11-05T13:37:32.035431Z"
    }
   },
   "id": "47d66c2c4917dcc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "52d2cc01d10cfa1a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Let's write a simple intent matching function using NLTK in Python for a restaurant booking system.\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "message = 'Hi I would like to book for two people today at 7pm. Also cancel my booking for 6'\n",
    "\n",
    "# Define a set of intents\n",
    "intents = {\n",
    "    \"greeting\": [\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"howdy\"],\n",
    "    \"booking\": [\"book\", \"make a reservation\", \"reserve\", \"booking\",\"appointment\"],\n",
    "    \"cancellation\": [\"cancel\", \"cancel reservation\", \"cancel booking\"],\n",
    "    \"menu\": [\"show menu\", \"menu\", \"what do you have\", \"what's on the menu\", \"what is there on the menu\", \"what food \"\n",
    "                                                                                                         \"is there\",\n",
    "             \"what specials are there\", \"what food do you have\"],\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T01:06:29.774137Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'would', 'like', 'book', 'two', 'people', 'today', '7pm']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "print(preprocess_text(message))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T01:06:40.390119Z",
     "start_time": "2023-11-05T01:06:40.381704Z"
    }
   },
   "id": "133da812925de839"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greeting': 1, 'booking': 1, 'cancellation': 0, 'menu': 0}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the message: tokenizes, removed punctuation, lemmatised to root word\n",
    "tokens = preprocess_text(message)\n",
    "\n",
    "# Tag the tokens with part of speech. Creates an array of tuples\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Calculate the score for each intent based on word matches\n",
    "intent_scores = {intent: 0 for intent in intents} # Create dictionary set to 0 for every intent determined above \n",
    "for word, pos in pos_tags:\n",
    "    if pos in ['VB', 'NN']:  # Consider only verbs and nouns for intent matching, using Part Of Speech tagging \n",
    "        for intent, keywords in intents.items(): # .items() creates list format of intent and array of keywords\n",
    "            if lemmatizer.lemmatize(word) in keywords:\n",
    "                intent_scores[intent] += 1\n",
    "\n",
    "# Find the intent with the highest score\n",
    "best_intent = max(intent_scores, key=intent_scores.get)\n",
    "\n",
    "print(intent_scores)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T01:20:24.364066Z",
     "start_time": "2023-11-05T01:20:24.328934Z"
    }
   },
   "id": "fa54b70726fab5a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notes to consider through all\n",
    "\n",
    "- Preprocessing: lemmatisation vs stemmatisation; which works better in my program? 1 is quicker\n",
    "- NLTK.download stuff: do we need to do this at the beginning?\n",
    "- Natural convo; ask questions back\n",
    "- \n",
    "- In main.py, derive intent, ask for **clarification** if one is not obvious\n",
    "-       First part of the flow diagram: intent matching?\n",
    "\n",
    "-Typo corrections from user input: bookng -> booking, otherwise it will be missed completely\n",
    "-Remember names, identity "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61706446c23083df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# bIGRAM INTENT MATCHING?\n",
    "\n",
    "- Avoid situations where counting 'keywords' is ambiguous with bigrams, ie make booking vs cancel booking\n",
    "**Issues with this:** What if someone starts the sentence with What is your/my name? or How is the weather today?\n",
    "- Consider by n-grams rather than just 1 word, **'make booking'**  vs **'cancel booking'** are completely different intents. Also, see bookings / **'alter booking'**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f8657274bf1ce5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question Answering \n",
    "- Vectorized : we want to choose the next word based similarity, only have answers?, this way the question wont be returned only. But surely its more helpful to identify the CLOSEST question-> look up its answer with the index\n",
    "-   - Use lab2 indexing 5. The Search General Algorithm looks useful, but consider 'documents' as sentence tokens (the answers). highest cosine similarity gets picked!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a92846313d13ecde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "15e35b1d8838d4df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
